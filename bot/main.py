import re
import asyncio
import aiohttp

from aiogram import Bot, Dispatcher, types, F
from aiogram.types import ContentType, InlineKeyboardButton, InlineKeyboardMarkup
from aiogram.filters import CommandStart, Command
from aiogram.enums.parse_mode import ParseMode

from urllib.parse import urlparse


API_TOKEN = '5809025995:AAGurQ4i-Y8OdParI5xDjGaxCe3ghfOFAlQ'
AUTHORIZED_PASSWORD = 'Start123'
FASTAPI_URL = 'http://api:8000/api/v1/scrapyd'

# –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ–º–µ–Ω–∞
DOMAIN_REGEX = re.compile(r'https?://(www\.)?([^/]+)')

# –°–ø–∏—Å–æ–∫ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤
ALLOWED_DOMAINS = ['reuters.com', 'ft.com', 'thenationalnews.com', 'wsj.com']

# –°–ø–∏—Å–æ–∫ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤
DOMAIN_SPIDER_MAP = {
    'reuters.com': 'reuters_spider',
    'ft.com': 'ft_spider',
    'thenationalnews.com': 'national_spider',
    'wsj.com': 'wsj_spider'
}

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞ –∏ –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞
bot = Bot(token=API_TOKEN)
dp = Dispatcher()

# –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
authorized_users = set()


# –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —á–µ—Ä–µ–∑ FastAPI
async def trigger_scrapy_spider(spider_name, url):
    async with aiohttp.ClientSession() as session:
        async with session.post(f'{FASTAPI_URL}/schedule/', json={'spider': spider_name, 'url': url}) as response:
            if response.status == 200:
                data = await response.json()
                return data.get('jobid')
            return 'Error: Failed to start scraping.' # !!!!!!!

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞—É–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –¥–æ–º–µ–Ω–∞
def get_spider_name_by_domain(url):
    domain = urlparse(url).netloc
    if 'reuters.com' in domain:
        return 'reuters_spider'
    elif 'ft.com' in domain:
        return 'ft_spider'
    elif 'thenationalnews.com' in domain:
        return 'national_spider'
    elif 'wsj.com' in domain:
        return 'wsj_spider'
    return None


# –ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ —Å –æ–ø—Ü–∏—è–º–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —Å—Ç–∞—Ç—å–∏ –∏–ª–∏ —Å—Å—ã–ª–∫–∏ –Ω–∞ Telegraph
def item_options_markup(job_id: str):
    return InlineKeyboardMarkup(inline_keyboard=[[
        InlineKeyboardButton(
            text='üì∞ –ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏',
            callback_data=f'get_text:{job_id}'
        )
    ], [
        InlineKeyboardButton(
            text='üîó –ü–æ–ª—É—á–∏—Ç—å —Å—Å—ã–ª–∫–∞ –Ω–∞ —Å—Ç–∞—Ç—å—é',
            callback_data=f'get_link:{job_id}'
        )
    ]])


# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start
@dp.message(CommandStart())
async def start(message: types.Message):
    await message.answer(
        '–ü—Ä–∏–≤–µ—Ç! üëã –î–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–æ—Ç–æ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ '
        '–∞–≤—Ç–æ—Ä–∏–∑–æ–∞—Ç—å—Å—è —Å –ø–æ–º–æ—â—å—é –∫–æ–º–∞–Ω–¥—ã /login <–ø–∞—Ä–æ–ª—å>'
    )


# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /login
@dp.message(Command('login'))
async def login_command(message: types.Message):
    try:
        password = message.text.split()[1]
    except IndexError:
        await message.answer(
            '‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É –≤ —Ñ–æ—Ä–º–∞—Ç–µ /login <–ø–∞—Ä–æ–ª—å>.'
        )
        return

    if password == AUTHORIZED_PASSWORD:
        authorized_users.add(message.from_user.id)
        await message.answer(
            '–í—ã —É—Å–ø–µ—à–Ω–æ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω—ã! üëç\n'
            '–¢–µ–ø–µ—Ä—å –í—ã –º–æ–∂–µ—Ç–µ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —Å—Å—ã–ª–∫–∏ '
            '–¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å—Ç–∞—Ç–µ–π.'
        )
    else:
        await message.answer('‚õî –ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å.')


# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å—Ç–∞—Ç—å—é
@dp.message()
async def handle_message(message: types.Message):
    if message.from_user.id not in authorized_users:
        await message.answer(
            '‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∞–≤—Ç–æ—Ä–∏–∑—É–π—Ç–µ—Å—å —Å –ø–æ–º–æ—â—å—é –∫–æ–º–∞–Ω–¥—ã /login.'
        )
        return

    url = message.text
    domain_match = DOMAIN_REGEX.search(url)
    if not domain_match:
        await message.answer(
            '‚ö†Ô∏è –≠—Ç–æ –Ω–µ –ø–æ—Ö–æ–∂–µ –Ω–∞ —Å—Å—ã–ª–∫—É.\n\n'
            '–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é —Å—Å—ã–ª–∫—É.'
        )
        return

    domain = domain_match.group(2)
    if domain not in ALLOWED_DOMAINS or not DOMAIN_SPIDER_MAP.get(domain):
        await message.answer(
            f'‚ö†Ô∏è –î–æ–º–µ–Ω {domain} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è.\n\n'
            f'–í–≤–µ–¥–∏—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ —Å—Ç–∞—Ç—å—é —Å –æ–¥–Ω–æ–≥–æ –∏–∑ —Å–∞–π—Ç–æ–≤: {", ".join(ALLOWED_DOMAINS)}.'
        )
        return

    spider_name = DOMAIN_SPIDER_MAP.get(domain)

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ —Å—Ç–æ—Ä–æ–Ω–Ω–∏–π —Å–µ—Ä–≤–∏—Å –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
    async with aiohttp.ClientSession() as session:
        async with session.post(
            f'{FASTAPI_URL}/schedule/',
            json={'spider_name': spider_name, 'url': url}
        ) as response:
            if response.status == 200:
                data = await response.json()
                return await message.answer(
                    '–ü—Ä–æ—Ü–µ—Å—Å –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å—Ç–∞—Ç—å–∏ –∑–∞–ø—É—â–µ–Ω.\n'
                    '‚è±Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ...',
                    reply_markup=item_options_markup(data['job_id']),
                    parse_mode=ParseMode.HTML
                )
            return await message.answer(
                '‚ÄºÔ∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø–∞—Ä—Å–µ—Ä–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.'
            )


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–∂–∞—Ç–∏–π –Ω–∞ –∫–Ω–æ–ø–∫–∏
@dp.callback_query()
async def callback_query_handler(call: types.CallbackQuery):
    action, job_id = call.data.split(':')
    if action == 'get_text':
        async with aiohttp.ClientSession() as session:
            async with session.get(
                    f'{FASTAPI_URL}/status/{job_id}') as response:
                if response.status == 200:
                    data = await response.json()
                    message = (f'<b>{data.get("title")}</b>\n\n'
                               f'{data.get("text")}')
                else:
                    message = '‚è±Ô∏è –ù–æ–≤–æ—Å—Ç—å –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è'
        await call.message.answer(message, parse_mode=ParseMode.HTML)
    elif action == 'get_link':
        async with aiohttp.ClientSession() as session:
            async with session.get(f'{FASTAPI_URL}/status/{job_id}') as response:
                if response.status == 200:
                    data = await response.json()
                    message = (f'<b>{data.get("title")}</b>\n\n'
                               f'{data.get("telegraph_url")}')
                else:
                    message = '‚è±Ô∏è –ù–æ–≤–æ—Å—Ç—å –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏'
        await call.message.answer(message, parse_mode=ParseMode.HTML)


async def main():
    # –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
    await dp.start_polling(bot)


if __name__ == '__main__':
    asyncio.run(main())
